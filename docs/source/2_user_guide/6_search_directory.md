<br>

# Search Directory

The `SearchDirectory` class contains the end-to-end functionality that can create a searchable database from a directory that can retrieve documents with similar semantic meanings to user inputted queries.

<br>

## File Structure

The functions contained within `SearchDirectory` are designed to manipulate existing data and store it in formats that lend themselves better search features. All of the files created will be stored in the folder specified when the `SearchDirectory` object is created. For example, if the following code is run it will create a `SearchDirectory` object that saves any files that it creates to `path/to/folder`.

```python
from file_processing import SearchDirectory
search = SearchDirectory("path/to/folder")
```

If there are already files contained in `path/to/folder`, such as a `.faiss` file, it will be able to read and load these files so that previous steps do not need to be recomputed.

Once all steps are completed, the following files will be contained in the specified folder:

| File | Generated by | Purpose |
| ---- | ------------ | ------- |
| `report.csv` | `report_from_directory()` | Contains text info and metadata from files in a given directory |
| `data_chunked.csv` | `chunk_text()` | Contains the chunked text data and corresponding file paths |
| `setup_data.json` | `chunk_text() and `load_embedding_model()` | Contains the number of chunks and the name of the embedding model being used |
| `embedding_batches/` | `embed_text()` | Contains embedding batches in the form of `.npy` files |
| `embeddings.npy` | `embed_text()` | Contains the complete embeddings of the chunks data |
| `index.faiss` | Any of the create index functions | Contains the embeddings in the form of a searchable FAISS index |

<br>

## Generating Report

If working with a directory of files, the `report_from_directory()` function generates a `report.csv` file that contains the text and metadata of any text-based files in that directory.

```python
from file_processing import SearchDirectory
search = SearchDirectory("path/to/folder")
search.report_from_directory("text/documents/directory/path")
```

<br>

## Chunking Text
Parameters - `input_file_path`, `document_path_column`, `document_text_column`, `chunk_size`, `chunk_overlap`

Many embedding models and LLMs have a limited context window. This means any large text files need to be broken down into chunks before being passed into these models. The `chunk_text()` method is used for this purpose.

It takes a `.csv` file containing a text field and a file path field as input. The `document_path_column` and `document_text_column` parameters are used to specify the column names in the `.csv`.

```python
from file_processing import SearchDirectory
search = SearchDirectory("path/to/folder")
search.chunk_text("path/to/csv/file.csv",
                  document_path_column="file path",
                  document_text_column="content")
```

Alternatively, if a `report.csv` file was already generated and is contained in the folder then no `.csv` file needs to be specified and the function will use the `report.csv` file as the input.

```python
from file_processing import SearchDirectory
search = SearchDirectory("path/to/folder")
search.report_from_directory("text/documents/directory/path")
search.chunk_text()
```

Both of these approaches will produce a chunked CSV file.
